{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Command-line interface proxy for SLURM REST API","text":"<p>The SLURM CLI-API Proxy client is a tool designed to bridge existing applications and scripts that rely on the SLURM CLI. The tool mimics traditional SLURM CLI commands (like sbatch and squeue), translating them into REST API calls. This enables seamless integration of existing tools with external SLURM workload managers. Anywhere where a setup assumes the SLURM CLI is available on a host, the SLURM CLI-API Proxy could help offload job processing to a more powerful system.</p> <pre><code>graph TD\n\n\n    LocalScript --&gt; sinfop\n    LocalScript --&gt; sbatchp\n    LocalScript --&gt; squeuep\n    LocalScript --&gt; scontrolp\n\n\n    Users --&gt;|SSH| sinfo[sinfo];\n    Users --&gt;|SSH| sbatch[sbatch];\n    Users --&gt;|SSH| squeue[squeue];\n    Users --&gt;|SSH| scontrol[scontrol];\n    Users --&gt; sinfop\n    Users --&gt; sbatchp\n    Users --&gt; squeuep\n    Users --&gt; scontrolp\n\n    sinfop[sinfo*] --&gt; |HTTP Request| slurmrestd;\n    sbatchp[sbatch*] --&gt; |HTTP Request| slurmrestd;\n    squeuep[squeue*] --&gt; |HTTP Request| slurmrestd;\n    scontrolp[scontrolp*] --&gt; |HTTP Request| slurmrestd;\n\n\n    subgraph \"Slurm controller\"\n        slurmrestd --&gt; slurmctld[slurmctld];\n        slurmctld --&gt; slurmdbd[slurmdbd];\n        sinfo --&gt; slurmctld;\n        sbatch --&gt; slurmctld;\n        squeue --&gt; slurmctld;\n        scontrol --&gt; slurmctld;\n    end\n\n    subgraph \"Compute Node\"\n        slurmd1[slurmd] \n    end\n\n    subgraph \"Compute Node\"\n        slurmd2[slurmd]\n    end\n\n    slurmctld --&gt; slurmd1;\n    slurmctld --&gt; slurmd2;\n\n    slurmdbd --&gt; Database[\"Slurm Accounting Database\"];</code></pre> <p>Examples of use cases for this tool, in the biomedical domain, include the Galaxy Pulsar project, a distributed job execution system that enables Galaxy servers to run computational tasks on remote systems, and Arvados, an open-source platform designed for managing and processing large-scale biomedical data.</p> <p>For instance, on public HPC Systems like the Dutch Snellius supercomputer, the SLURM CLI is only available on nodes that are not intended for running services like Galaxy Pulsar or Arvados. Hence, enabling these platforms to offload computing tasks to Snellius requires multiple networking/tunneling tweaks, something that is not desirable on an HPC research infrastructure.</p> <p>While refactoring platforms like Arvados to make it use the SLURM REST API instead of the CLI is an option to address this connectivity challenge, the complexity and scale of its codebase make the SLURM CLI-API Proxy client a more cost-effective solution, as it enables the use of the API without requiring any modifications on the existing codebase.</p>"},{"location":"addingargs/","title":"Extending already supported commands with new arguments","text":""},{"location":"addingargs/#commands-that-require-using-the-argument-values-as-part-of-the-request-payload-sbatch-scontrol","title":"Commands that require using the argument values as part of the request payload (sbatch, scontrol)","text":"<p>Given the design principles previously described, adding argument to a command, already configured for a given API version (in this case, v0.0.39) involves the following steps:</p> <ol> <li> <p>Check the target API resource used by the command's proxy, its corresponding API client method, and the related data objects. For example, the <code>sbatch</code> proxy command currently implemented performs a POST request to <code>/slurm/v0.0.39/job/submit</code>.</p> Command VERB + Target SLURM API resource OpenAPI Client method Related data classes sbatch POST /slurm/v0.0.39/job/submit slurm_v0039_submit_job V0039JobSubmission, V0039JobDescMsg (request payload) squeue GET /slurm/v0.0.39/jobs slurm_v0039_get_jobs V0039JobsResponse (request response) scontrol UPDATE /slurm/v0.0.39/job/{job_id} slurm_v0039_update_job V0039JobDescMsg (request payload) sinfo GET /slurm/v0.0.39/partitions, GET /slurm/v0.0.39/nodes slurm_v0039_get_partitions V0039PartitionsResponse (request response) </li> <li> <p>Check which property of the corresponding POST payload should be set to the value given to the argument. To this end, look at the documentation of the class used for creating the request's payload. For example, the POST payload structure required by the <code>/slurm/v0.0.39/job/submit</code> resource is defined by the V0039JobDescMsg class. </p> </li> <li> <p>Based on the above, add an entry on the existing YAML configuration file of the <code>sbatch</code> command (<code>mappings/sbatch_mappings_r23.11_v0.0.39.yaml</code>). For example, to add support to the <code>--chdir</code> argument (which defines in which directory within the SLURM worker the script will be executed), you can verify that the its equivalent on theV0039JobDescMsg class is the <code>current_working_directory</code> property. Based on this, the argument should be included as follows: </p> <pre><code>- name: --chdir\n  abbreviation: -D\n  is_mandatory: false\n  data_type: str\n  api_mapping:\n      request_property: job.current_working_directory\n</code></pre> <p>Keep in mind that the accepted values for data_type are int, str and bool. When using the latter, argparse uses it as a flag, so no value is captured for it. </p> </li> <li> <p>And that's it! However, if the captured argument value needs to be pre-processed, you can include a lambda expression to do it if needed. For example, the <code>--export</code> argument (the environment variables to be exported), in the <code>sbatch</code> command receives a string with comma-separated values, but the V0039JobDescMsg class requires a list of strings (that is, each exported environment variable).</p> <p>By including the following definition on the <code>sbatch</code> YAML configuration file:</p> <pre><code>- name: --export\n  abbreviation: --export\n  is_mandatory: false\n  data_type: str\n  api_mapping:\n      request_property: job.environment\n      lambda_expression: \"lambda p: p.split(',')\"\n</code></pre> <p>The following request payload would be generated:</p> <pre><code>//Payload generated for the command: sbatch script1.sh --export PATH=/bin/,ENV2=123 --job-name job123\n\n{\n    \"script\": \"&lt;the content of script1.sh&gt;\",  \n    \"job\": {\n        \"environment\": [\"PATH=/bin/\",\"ENV2=123\"],\n        \"name\": \"job123\"\n    }\n}\n</code></pre> </li> </ol>"},{"location":"addingargs/#commands-that-require-using-the-argument-values-for-output-formatting-only-squeue-sinfo","title":"Commands that require using the argument values for output formatting only (squeue, sinfo)","text":"<p>The proxies of commands like <code>squeue</code> or <code>sinfo</code> use the arguments only for formatting purposes. For example, a <code>GET</code> request to the <code>/slurm/v0.0.39/jobs</code> (as it doesn't support any arguments), simply return all the jobs as a V0039JobsResponse object. Hence, to mimic the behaviour of arguments like <code>--user</code>, this V0039JobsResponse must be pre-processed to produce a string -the one that will be sent to STDOUT- that is consistent with such command. </p> <p>This can be done on the corresponding client wrapper method, which, as described on the design principles section, is where the request is performed using the API client, and response processed. You can check which wrapper is being used by looking at the <code>wrapper_package</code> and <code>wrapper_class</code> on the command's YAML configuration file. </p> <p>For example, the <code>squeue_get_request</code> method of the <code>V39SlurmAPIClientWrapper</code> class, listed below, transforms the given V0039JobsResponse, into a string that mimics the <code>squeue</code> output. For this it considers the details included on the list of V0039JobInfo objects given on its jobs property. Hence, to do the output pre-processing considering the <code>--user</code> argument, this method should check if this argument was included on the <code>cli_arguments</code> dictionary, which value (the user) was given to it, and filter the jobs whose <code>user_id</code> is equal to such value:</p> <pre><code>def squeue_get_request(self,cli_arguments:dict,conf:openapi_client.Configuration,slurmrestd_token:str)-&gt; SqueueResponse:    \n    configuration = conf\n    configuration.api_key['token'] = slurmrestd_token\n\n    with openapi_client.ApiClient(configuration) as api_client:\n        # Create an instance of the API class\n        api_instance = openapi_client.SlurmApi(api_client)\n        #update_time = 56 # int | Filter if changed since update_time. Use of this parameter can result in faster replies. (optional)\n\n        try:\n            # get list of jobs\n            api_response:V0039JobsResponse = api_instance.slurm_v0039_get_jobs()                \n\n            ######################################\n            ######## TRANSFORM api_response_dict into a string, based on:\n            ########  * the api response\n            ########  * the cli_arguments            \n            output:str = ...\n            ######################################\n\n            if (api_response.errors is not None):\n                #Transform list of list[V0039Error] to list[str] \n                errors:list[str] = list(map(lambda err: str(err), api_response.errors))\n            else:\n                errors = []\n\n            if (api_response.warnings is not None):\n                #Transform list of list[V0039Warning] to list[str] \n                warnings:list[str] = list(map(lambda err: str(err), api_response.warnings))\n            else:\n                warnings = []\n\n            return SqueueResponse(output=output,errors=errors,warnings=warnings)\n\n        except Exception as e:       \n            raise ApiClientException(f'Unexpected error while performing a GET request for the squeue command:{e}') from e                \n</code></pre>"},{"location":"addingcommands/","title":"Adding new commands","text":"<p>The current version of the tool provides proxies for the <code>sbatch</code>, <code>squeue</code> and <code>scontrol</code>, commands, with a selection of their respective arguments. In the process of inclusing these, there were further design considerations for simplyfing as much as possible the inclusion of additional SLURM commands. These design considerations, along with the suggested steps for adding a new command, are below described, with <code>sinfo</code> as a reference example.</p> <ol> <li> <p>As the first step, identify wich resources of the SLURM API can be used to replicate the new command. Using the examples included in the documentation, make experiments with the API client to understand what is required by the payload, the structure of the API response, etc. The <code>sinfo</code> requires performing GET requests to <code>/slurm/v0.0.39/partitions</code> and <code>/slurm/v0.0.39/nodes</code> resources, hence you can refer to the slurm_v0039_get_nodes and slurm_v0039_get_partitions functions documentation. As you will see, the V0039NodesResponse provides details of every node, including the list of the partitions each one belongs to, whereas theV0039PartitionsResponse gives the detais of such partitions. Use these code examples to create a minimum python script that performs a request to these two resources and print the 'raw' output.</p> </li> <li> <p>To run the script, update the host and api_key properties so that they match your target test SLURM server:</p> <pre><code>configuration = openapi_client.Configuration(\n    host = \"http://&lt;slurm-controllers-name&gt;:6820\"\n)\n\nconfiguration.api_key['token'] = os.environ[\"SLURM_JWT\"]\n</code></pre> </li> <li> <p>Create a new YAML file for the command on <code>src/mappings</code> (all the YAML files here are copied to the Python package data, as seen on the <code>setup.py</code> file). By convention, to ensure that a cli parser is properly created for the new command, each argument must include the name, abbreviation, is_mandatory, and type elements:</p> <pre><code>mapping_meta:\ncommand: sinfo\napi_version: 0.0.39\nwlm_release: 23.11\nwrapper_package: slurm_api_cli_proxy.client_args_linker.v39.slurm_api_client_wrapper_v39\nwrapper_class: V39SlurmAPIClientWrapper\n\nparameters:\n\n- name: \n    abbreviation: \n    is_mandatory: \n    type:\n</code></pre> </li> <li> <p>Now you need to create a new method on the client wrapper that performs the API request, for a given API version, required by the new proxy command. This method must return an <code>SlurmCommandResponse</code> object, which contains the command's output to be printed on STDOUT, along with the errors and warnings reported by SLURM in the process. As it will use the API client required for that particular API version, its implementation can be based on the python example you created on step 1. </p> <p>Add an abstract method for the new command on the client wrapper interface (<code>SlurmAPIClientWrapper</code>), and add its implementation on the <code>V39SlurmAPIClientWrapper</code> (a class that implements the <code>SlurmAPIClientWrapper</code> interface). This method should include as parameters, at least, an <code>openapi_client.Configuration</code> and the slurm API token. The method created for the <code>sinfo</code> command also includes a dictionary with the CLI arguments, so its output can be properly formatted before including it on the returned <code>SlurmCommandResponse</code> object (other POST-based commands like <code>squeue</code> would also require a dictionary for creating the request's JSON payload).</p> <p>It is also important to consider that, by convention, any exception catched within the method should be scaled as an <code>ApiClientException</code> so that they are properly handled by the application:</p> <pre><code>def sinfo_get_request(self,cli_arguments:dict,conf:openapi_client.Configuration,slurmrestd_token:str)-&gt; SlurmCommandResponse:\n    configuration = conf\n    configuration.api_key['token'] = slurmrestd_token\n\n    with openapi_client.ApiClient(conf) as api_client:    \n        api_instance = openapi_client.SlurmApi(api_client)\n\n        try:\n\n            api_response:V0039PartitionsResponse = api_instance.slurm_v0039_get_partitions()\n\n            if (api_response.errors is not None):\n                #Transform list of list[V0039Error] to list[str] \n                errors:list[str] = list(map(lambda err: str(err), api_response.errors))\n            else:\n                errors = []\n\n            if (api_response.warnings is not None):\n                #Transform list of list[V0039Warning] to list[str] \n                warnings:list[str] = list(map(lambda err: str(err), api_response.warnings))\n            else:\n                warnings = []\n\n            ################################\n            # Transform the request's response (api_response) into a string (output)\n            # that resembles the format used by the real SLURM commands, based on the\n            # arguments given in cli_arguments:\n            output = ...\n            #\n            #################################\n\n            return SlurmCommandResponse(output=output,errors=errors,warnings=warnings)\n\n        except Exception as e:\n            raise ApiClientException(f'Unexpected error while performing a GET request for the squeue command:{e}') from e \n</code></pre> </li> <li> <p>Now that you have a client wrapper method for the command, it's time to implement what put everything together: a command evaluator which parses the arguments given through the CLI, prepares the request payload (if needed) based on such arguments and the settings given on the YAML configuration file, and uses this client wrapper to perform the request. Most of this is already implemented on the <code>slurm_api_cli_proxy.command_handler.CommandEvaluator</code> class, so for a new command only a subclass implementing the <code>process_command_args</code> method is required. </p> <pre><code>---\ntitle: asds\n---\nclassDiagram\n\n    class CommandEvaluator {\n        + (abstract) process_command_args(...) SlurmCommandResponse\n        + eval_command(self, config_file_path, include_input_file_arg)\n        - __get_env_vars(self) Tuple[str, str]\n    }\n\n    class SbatchEvaluator {\n        + process_command_args(...) SlurmCommandResponse\n    }\n\n    class SqueueEvaluator {\n        + process_command_args(...) SlurmCommandResponse\n    }\n\n    class ScontrolEvaluator {\n        + process_command_args(...) SlurmCommandResponse\n    }\n\n    CommandEvaluator &lt;|-- SbatchEvaluator\n    CommandEvaluator &lt;|-- SqueueEvaluator\n    CommandEvaluator &lt;|-- ScontrolEvaluator\n\n</code></pre> <p>The following example, for the <code>sinfo</code> command, describe the method's arguments, and how these can be used to perform the request base on the given arguments:</p> <pre><code>class SinfoEvaluator(CommandEvaluator):\n\n    def process_command_args(self,\n    #the wrapper defined on the YAML file will be set here\n    slurm_cli_wrapper:SlurmAPIClientWrapper,\n    #the dictionary with the CLI arguments given by argparse\n    cli_args,\n    #an object representation of the YAML configuration file\n    command_mappings_config:CliToJsonPayloadMappings,\n    #the configuration required to create an instance of the client\n    configuration:openapi_client.Configuration,\n    #the SLURM API web token\n    slurm_jwt:str)-&gt;SlurmCommandResponse:    \n\n        #dictionary with the arguments/values given to the squeue command\n        request_args = args_to_parameters_dict(command_args_dict=vars(cli_args))\n\n        response = slurm_cli_wrapper.sinfo_get_request(request_args, \n        configuration,slurm_jwt)\n\n        return response\n</code></pre> </li> <li> <p>On the <code>command_handler</code> add the function that make use of the Command Evaluator, which can be used for linking it with the proxy command's entry point. As seen in the example, here you refer to the YAML configuration file originally created:</p> <pre><code>def sinfo():\n\n    eval = SinfoEvaluator()\n    eval.eval_command(config_file_path='mappings/sinfo_mappings_r23.11_v0.0.39.yaml')    \n</code></pre> </li> <li> <p>Link the method above to an entry point that corresponds to the original command name:     <pre><code>    #setup.py\n    ...\n    entry_points={\n        \"console_scripts\": [\n            \"sbatch=slurm_api_cli_proxy.command_handler:sbatch\",\n            \"squeue=slurm_api_cli_proxy.command_handler:squeue\",\n            \"scontrol=slurm_api_cli_proxy.command_handler:scontrol\",\n            \"sinfo=slurm_api_cli_proxy.command_handler:sinfo\",\n        ],\n    },\n</code></pre></p> </li> <li> <p>After rebuilding the package (<code>pip install .</code>), the new command should now be available.</p> </li> </ol>"},{"location":"alternateapiversion/","title":"Supporting alternative SLURM API versions","text":"<p>As described in the previous sections, this application's core is decoupled from any particular version of API client. All the implemented command handlers make reference to an abstract <code>SlurmAPIClientWrapper</code>, and the specific implementation to be used is defined at runtime depending on what's defined on the used YAML configuration files.</p> <p>Given this, adding support for an alternative version of the SLURM API would require, in principle:</p> <ol> <li>Creating a new class that implements the <code>SlurmAPIClientWrapper</code> interface.</li> <li>Implementing all of its methods, which could be, for the most part, based on the existing implementations.</li> <li>Redefining new YAML files for each command, changing the mappings according to the new API specifications, and changing the <code>wrapper_class</code> accordingly.</li> </ol> <pre><code>---\ntitle: Client wrapper abstraction\n---\nclassDiagram\n\n    class V41SlurmAPIClientWrapper {\n        + sbatch_post_request(self, request, conf, slurmrestd_token) SbatchResponse\n        + scontrol_update_request(self, target_job_id, request, conf, slurmrestd_token) ScontrolResponse\n        + squeue_get_request(self, cli_arguments, conf, slurmrestd_token) SqueueResponse\n        + sinfo_get_request(self, cli_arguments, conf, slurmrestd_token) SinfoResponse\n    }\n\n    class V39SlurmAPIClientWrapper {\n        + sbatch_post_request(self, request, conf, slurmrestd_token) SbatchResponse\n        + scontrol_update_request(self, target_job_id, request, conf, slurmrestd_token) ScontrolResponse\n        + squeue_get_request(self, cli_arguments, conf, slurmrestd_token) SqueueResponse\n        + sinfo_get_request(self, cli_arguments, conf, slurmrestd_token) SinfoResponse\n    }\n\n\n    class SlurmAPIClientWrapper {\n        + sbatch_post_request(self, request, conf, slurmrestd_token) SbatchResponse\n        + squeue_get_request(self, cli_arguments, conf, slurmrestd_token) SqueueResponse\n        + sinfo_get_request(self, cli_arguments, conf, slurmrestd_token) SinfoResponse\n        + scontrol_update_request(self, target_job_id, request, conf, slurmrestd_token) ScontrolResponse\n    }\n\n    SlurmAPIClientWrapper &lt;|-- V39SlurmAPIClientWrapper\n    SlurmAPIClientWrapper &lt;|-- V41SlurmAPIClientWrapper</code></pre> <p>However, the scenario of adding support for new versions has not been explored in detail, and it may require further refinements on the tool design.</p>"},{"location":"designprinciples/","title":"Extending the SLURM CLI-API Proxy","text":""},{"location":"designprinciples/#cli-api-proxy-design-fundamentals","title":"CLI-API Proxy design fundamentals","text":"<p>The SLURM-CLI proxy is designed to enable scripts or platforms that depend on SLURM commands to interact with HPC infrastructure, even when those commands are not available locally\u2014such as in cases where the platform cannot be installed within the SLURM cluster. This tool acts as a proxy for SLURM commands by leveraging the SLURM REST API under the hood.</p> <p>Since each SLURM command can accept dozens or even hundreds of arguments\u2014many of which cannot be replicated through the API and are often unnecessary for these scripts or platforms\u2014this proxy does not aim to provide a complete implementation. Instead, it focuses on a practical subset of arguments that can be extended as needed.</p> <p>To support this extensibility, the tool is built in a way that it is decoupled from the specificities of each command's arguments, by generalizing how they are mapped to the arguments (payloads) of an API request. This way, adding a new argument only requires adding new values to a configuration file. However, for commands like <code>squeue</code> and <code>sinfo</code>, whose arguments are not used as the 'payload' but for formatting the command's ouput, the implementation of such formatting is required. </p> <p>The requests to the SLURM API are handled through an API client, generated using the OpenAPI Generator using the SLURM OpenAPI specification. The client included on <code>slurm_api_client</code> folder corresponds to the API of the SLURM's workload manager release 23.11, whose OpenApi specification is included on the <code>open_api_specs/slurm_0.0.38_39_40.yaml</code> folder.</p> <p>To illustrate the above, let's delve into the process that occurs when the <code>sbatch</code> proxy command is executed:</p> <ol> <li> <p>The CLI parser (<code>argparse</code>) is dynamically configured based on the arguments defined in the <code>sbatch</code> command's YAML configuration file (<code>mappings/sbatch_mappings_r23.11_v0.0.39.yaml</code>). As the file name suggests, this configuration is tailored to a specific SLURM API version (in this case, v0.0.39, corresponding to SLURM's workload manager release 23.11). For example, the properties defined in the configuration file below enable support for the <code>--export</code> and <code>--job-name</code> arguments, which are optional (<code>is_mandatory: false</code>) and expect string values (<code>data_type: str</code>):</p> <pre><code># mappings/sbatch_mappings_r23.11_v0.0.39.yaml\n\n- name: --job-name\n  abbreviation: -J\n  is_mandatory: false\n  data_type: str\n  api_mapping:\n    request_property: job.name\n</code></pre> </li> <li> <p>The CLI parser, in addition to check the consistency of the command, capture the values given to these arguments by the user.</p> </li> <li> <p>The captured argument values are used to build the payload required by the POST request (given properties set on the <code>api_mapping</code> element) to the correspondig target SLURM API resource (<code>POST /slurm/v0.0.39/job/submit</code>). This <code>api_mapping</code> must be consistent with the payload that is expected to be submitted with this request. In this case, the API client uses the V0039JobSubmission class, which in turn has a 'job' property of type V0039JobDescMsg with a 'name' property for defining the job name of the request. Setting <code>api_mapping/request_property</code> to <code>job.name</code> for the <code>--job-name</code> argument ensure that the value given to the this argument will be set on the corresponding payload property.</p> <p>For example, based on the sample configuration above, when running the command:<code>sbatch script1.sh --job-name job123</code>, the following JSON payload is generated:</p> <pre><code>//Payload generated for the command: sbatch script1.sh --job-name job123\n\n{\n    \"script\": \"&lt;the content of script1.sh&gt;\",  \n    \"job\": {\n        \"name\": \"job123\"\n    }\n}\n</code></pre> </li> <li> <p>The actual request to the SLURM API is performed by a client wrapper, which is also defined in the sbatch's command YAML file. This class encapsulates the logic required to perform the request, with a given API client, for a specific API version, using the payload generated from the argument values. </p> </li> <li> <p>As the mappings on the YAML file corresponds to the version v0.0.39 of the API, the (<code>wrapper_class</code>) property is also set to use a wrapper implemented for that particular API version.</p> <pre><code># mappings/sbatch_mappings_r23.11_v0.0.39.yaml\n\nmapping_meta:\n  command: sbatch\n  api_version: 0.0.39\n  wlm_release: 23.11\n  wrapper_package: slurm_api_cli_proxy.client_args_linker.v39.slurm_api_client_wrapper_v39\n  wrapper_class: V39SlurmAPIClientWrapper\n\n...\n</code></pre> </li> <li> <p>Finally, the response to the API request is pre-processed (e.g., handling HTTP error codes, error messages, etc). These results are printed to STDOUT, and the execution is finished with the appropriate error code (e.g., 0 when the command is successful).</p> </li> </ol> <p>The following sequence diagram describes the above with more specific module and classes references:</p> <pre><code>sequenceDiagram\n    actor SLURM client\n    SLURM client -&gt;&gt; Linux CLI: sbatch\n    Linux CLI -&gt;&gt; command_handler: sbatch()    \n    command_handler -&gt;&gt; command_handler: load YAML config for SLURM API v.X.Y\n\n    command_handler -&gt;&gt; arguments_evaluator: parser = build_cli_args_parser(YAML_file_content)\n\n    command_handler -&gt;&gt; command_handler: args = parser.parse()\n\n    command_handler -&gt;&gt; client_args_linker.args_to_payload_mapper : api_req_payload = args_to_sbatch_request_payload(args)\n\n    command_handler -&gt;&gt; slurm_api_client_wrapper: api_wrapper = get_slurm_api_client_wrapper(YAML_config)\n\n    command_handler -&gt;&gt; api_wrapper(SlurmAPIClientWrapper): sbatch_post_request(api_req_payload)\n    api_wrapper(SlurmAPIClientWrapper) -&gt;&gt; SLURM API: reponse &lt;- HTTP POST request\n\n    command_handler -&gt;&gt; command_handler: print response to STDOUT\n</code></pre>"},{"location":"devprocess/","title":"Continious integration","text":""},{"location":"devprocess/#unit-and-integration-tests","title":"Unit and integration tests","text":"<pre><code>#Start a dockerized slurm cluster on localhost (works on Linux only)\nsource src/tests/slurm_test_scripts/start_dockerized_slurm.sh\n\n#Run tests \npytest\n</code></pre>"},{"location":"devprocess/#running-unit-tests-only-doesnt-require-the-dockerized-slurm-cluster","title":"Running unit tests only (doesn't require the dockerized slurm cluster)","text":"<pre><code># Run tests, excluding integration ones (which require the dockerized slurm cluster running on localhost)\npytest -m \"not integration\"\n</code></pre>"},{"location":"devprocess/#static-type-checking","title":"Static type checking","text":"<pre><code>#Static type checking with mypy. \nmypy src --check-untyped-defs\n</code></pre>"},{"location":"devprocess/#version-management","title":"Version Management","text":""},{"location":"devprocess/#overview","title":"Overview","text":"<p>This project uses trunk-based development with controlled releases. Versions are managed through a combination of semantic versioning and feature flags.</p> <pre><code>sequenceDiagram\n    participant D as Developer\n    participant M as Main Branch\n    participant R as Release Branch\n    participant P as Production\n\n    Note over D,P: Version Management Workflow\n\n    D-&gt;&gt;M: Direct commit to main\n    activate M\n    Note over M: Run CI/CD pipeline\n    alt Pipeline passes\n        M-&gt;&gt;P: Deploy to production\n    else Pipeline fails\n        P--&gt;&gt;M: Fix issues\n        M-&gt;&gt;P: Retry deployment\n    end\n\n\n    Note over M,R: Ready for release\n    M-&gt;&gt;R: Create release branch\n    activate R\n    Note over R: Update version in setup.py\n    Note over R: Stabilize &amp; prepare release\n    R-&gt;&gt;P: Deploy release\n    deactivate R\n\n    Note over P,M: Post-release\n    P--&gt;&gt;M: Backmerge release changes\n    Note over M: Increment version for next dev\n    deactivate M</code></pre>"},{"location":"devprocess/#version-update-process","title":"Version Update Process","text":""},{"location":"devprocess/#when-to-update-versions","title":"When to Update Versions","text":"<ul> <li>Update version in setup.py during release branch creation</li> <li>Increment version in main branch after release</li> <li>Use semantic versioning (major.minor.patch)</li> </ul>"},{"location":"devprocess/#release-workflow","title":"Release Workflow","text":"<ol> <li>Create release branch from main</li> <li>Update version in setup.py</li> <li>Stabilize and test</li> <li>Deploy to production</li> <li>Merge back to main</li> <li>Increment version for next development cycle</li> </ol>"},{"location":"devprocess/#main-branch-management","title":"Main Branch Management","text":"<ul> <li>Keep main branch always releasable</li> <li>Use feature flags for incomplete features</li> <li>Document version changes in changelog</li> <li>Maintain clear version history</li> </ul>"},{"location":"limitations/","title":"Limitations &amp; mismatches between the local CLI and the Proxy CLI","text":""},{"location":"limitations/#sbatch-v0039","title":"sbatch (v0.0.39)","text":"<ul> <li> <p>The real <code>sbatch</code> command validates the input script for inconsistencies (e.g., the first line not starting with start with #!) and prevent the job to be started. When using the sbatch proxy, the content of the script is submitted as part of the corresponding API request. Therefore, when inconsistent slurm scripts are used with the proxy, a new job will be started, and eventually fail once the slurmctld process it.</p> </li> <li> <p>The <code>sbatch</code> command sets the current path (where the command is executed) as the default value for <code>--chdir</code> if it is not defined explicitly. If the current path doesn't exist on the worker node where the job will be executed, the job will fail. To ensure consistency, the working <code>--chdir</code> argument should always be used with a path within the worker node:</p> <pre><code>sbatch --job-name dajob --chdir /home/hcadavid  tests/slurm_test_scripts/slurm_write_job.sh\n</code></pre> </li> </ul>"},{"location":"limitations/#scontrol-v0039","title":"scontrol  (v0.0.39)","text":"<ul> <li>Only job updates are supported. Node, partition and reservation resources are immutable in the SLURM API (only GET method).</li> <li>Only one job can be updated at a time: only the '/job/{job_id}' endpoint (for a single job) is available.</li> <li><code>scontrol</code> has an interactive mode when no command is given. The proxy doesn't support such a behaviour.</li> <li>It has been observed that updating 'nice' through the API may cause the slurmrestd daemon to crash.</li> </ul>"},{"location":"setup/","title":"Setup and usage","text":""},{"location":"setup/#requirements","title":"Requirements","text":"<ul> <li>Linux, MacOS or Windows with WSL</li> <li>Python version \u22653.10</li> </ul>"},{"location":"setup/#installation","title":"Installation","text":"<pre><code># Check python version (requiring \u22653.10)\npython --version\n\n# Create a new virtual environment\npython -m venv env\nsource env/bin/activate\n\n# install \npip install .\n</code></pre> <p>A virtual environment is required to install the the non-pypi dependencies. You can also use <code>conda</code> to manage python environments. If running from a shell terminal, the virtual environment where the package was installed must be active on it.</p>"},{"location":"setup/#testing","title":"Testing","text":""},{"location":"setup/#unit-and-integration-tests","title":"Unit and integration tests","text":"<pre><code>#Start a dockerized slurm cluster on localhost (works on Linux only)\nsource src/tests/slurm_test_scripts/start_dockerized_slurm.sh\n\n#Run tests \npytest\n</code></pre>"},{"location":"setup/#running-unit-tests-only-doesnt-require-the-dockerized-slurm-cluster","title":"Running unit tests only (doesn't require the dockerized slurm cluster)","text":"<pre><code># Run tests, excluding integration ones (which require the dockerized slurm cluster running on localhost)\npytest -m \"not integration\"\n</code></pre>"},{"location":"setup/#static-type-checking","title":"Static type checking","text":"<pre><code>#Static type checking with mypy. \nmypy src --check-untyped-defs\n</code></pre>"},{"location":"setup/#usage-from-a-shell-terminal","title":"Usage from a shell terminal","text":"<ol> <li>Define the URI of the target SLURM API through the <code>PROXY_SLURM_API_URL</code> environment variable:</li> </ol> <pre><code>#Example:\nexport PROXY_SLURM_API_URL=http://slurm-controller:6820\n</code></pre> <ol> <li>Set the SLURM_JWT environment variable with the API token of the target SLURM API. An script is provided to do this if you have ssh access to the SLURM workload manager:</li> </ol> <pre><code># Setting the SLURM_JWT variable (can be obtained by running 'scontrol token' on the SLURM workload manager)\nexport SLURM_JWT=&lt;token&gt;\n\n# Setting the SLURM_JWT variable through the provided script (password for opening an ssh session will be requested)\n# source update_token.sh &lt;slurm-wlm-user&gt; &lt;slurm-wlm-host&gt;. E.g.:\nsource update_token.sh userx slurm-controller\n</code></pre> <ol> <li>Run slurm commands as you would do* with the real ones:</li> </ol> <pre><code>#sbatch help\nsbatch --help\n\n#request a job defined on a shell script\nsbatch --job-name jobx --chdir /home/userx  src/tests/slurm_test_scripts/slurm_write_job.sh\n\n#capture a job definition through STDIN and request its execution\nsbatch --job-name jobx --chdir /home/userx\n\n#show running jobs\nsqueue \n\n#show running jobs in json format\nsqueue --json\n\n#update a job\nscontrol update JobId=206 MinCPUsNode=1\n\n#hold/release a given job\nscontrol hold 209\nscontrol release 209\n</code></pre>"}]}